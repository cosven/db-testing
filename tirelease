#!/usr/bin/env python3

"""
Install requires
----------------

pip3 install aiohttp pyyaml requests click jira python-jenkins

Usage
-----

1. use GitHub CLI to generate token files, see https://cli.github.com/
2. setup your environment variables
  - TIDB_JENKINS_USERNAME
  - TIDB_JENKINS_PASSWORD
  - IDC_JENKINS_USERNAME
  - IDC_JENKINS_PASSWORD
  - QA_JENKINS_USERNAME
  - QA_JENKINS_PASSWORD
  - JIRA_USERNAME
  - JIRA_PASSWORD
  - GITHUB_TOKEN
3. run `./tirelease --help` to see more details
"""

import asyncio
import hashlib
import json
import re
import sys
import os
from collections import namedtuple
from enum import Enum
from functools import wraps

import aiohttp
import click
import yaml

from jinja2 import Template
from jira import JIRA
from jenkins import Jenkins, JenkinsException


class Project(Enum):
    tikv = 'tikv/tikv'
    tidb = 'pingcap/tidb'
    pd = 'pingcap/pd'
    tiflash = 'pingcap/tics'

    binlog = 'pingcap/tidb-binlog'
    tools = 'pingcap/tidb-tools'
    lightning = 'pingcap/tidb-lightning'

    importer = 'tikv/importer'
    br = 'pingcap/br'
    ticdc = 'pingcap/ticdc'


class Status(Enum):
    """Jenkins build status"""
    unknown = 'unknown'

    created = 'created'
    pending = 'pending'
    running = 'running'

    # finished
    succeed = 'succeed'
    failed = 'failed'


class JenkinsId(Enum):
    idc = 'idc'
    tidb = 'tidb'
    qa = 'qa'


class Job(Enum):
    e2e = 'tidb_and_tools_e2e_test'
    bench_manual = 'bench_manual'
    bench_tpcc = 'bench_tpcc_master'
    bench_tpch = 'bench_tpch_master'
    bench_ycsb = 'bench_ycsb'

    tiflash_regression = 'tiflash_regression_test_daily'
    tiflash_test = 'tiflash_schrodinger_test'

    build_tidb = 'build-tidb'
    build_tikv = 'build-tikv'
    build_pd = 'build-pd'
    build_all = 'build-all'


JenkinsJobsMapping = {
    JenkinsId.tidb: [],
    JenkinsId.idc: [Job.bench_manual,
                    Job.bench_tpcc,
                    Job.bench_tpch,
                    Job.bench_ycsb,
                    Job.tiflash_regression,
                    Job.tiflash_test,
                    Job.e2e],
    JenkinsId.qa: [Job.build_tidb,
                   Job.build_tikv,
                   Job.build_pd,
                   Job.build_all],
}

#: Jenkins build record
BuildRecord = namedtuple('BuildRecord', ['name', 'digest', 'url', 'status'])


TIDB_JENKINS_URI = 'https://internal.pingcap.net/tidb-jenkins'
TIDB_JENKINS_USERNAME = os.getenv('TIDB_JENKINS_USERNAME')
TIDB_JENKINS_PASSWORD = os.getenv('TIDB_JENKINS_PASSWORD')

IDC_JENKINS_URI = 'https://internal.pingcap.net/idc-jenkins'
IDC_JENKINS_USERNAME = os.getenv('IDC_JENKINS_USERNAME')
IDC_JENKINS_PASSWORD = os.getenv('IDC_JENKINS_PASSWORD')

QA_JENKINS_URI = 'http://172.16.4.61:30001'
QA_JENKINS_USERNAME = os.getenv('QA_JENKINS_USERNAME')
QA_JENKINS_PASSWORD = os.getenv('QA_JENKINS_PASSWORD')


DBFILE = 'pr2jira.db'
JENKINS_DBFILE = 'jenkins.db'

JIRA_URI = 'https://internal.pingcap.net/jira'
JIRA_USERNAME = os.getenv('JIRA_USERNAME')
JIRA_PASSWORD = os.getenv('JIRA_PASSWORD')

GITHUB_TOKEN_FILEPATH = os.path.expanduser('~/.config/gh/config.yml')

if os.path.exists(GITHUB_TOKEN_FILEPATH):
    with open(GITHUB_TOKEN_FILEPATH) as f:
        data = yaml.safe_load(f)
        GITHUB_TOKEN = data['hosts']['github.com']['oauth_token']
else:
    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')
    if GITHUB_TOKEN is None:
        raise Exception('please set GITHUB_TOKEN environment variable')

GITHUB_HEADERS = {"Authorization": f"token {GITHUB_TOKEN}"}

##################
# utils
##################

#: bugfix report template with jinja2 syntax
BUGFIX_REPORT_TEMPLATE = """
<html>
  <head>
    <style>
     table {
       max-width: 600px;
       border-collapse: collapse;
     }
     table, th, td{
       vertical-align: middle;
       border: 1px solid black;
     }
     th {
       text-align: center;
     }
     td {
       text-align: left;
       word-wrap: break-word;
     }
    </style>
  </head>
  <body>
    <table style="">
      <tr>
        <th>PR</th>
        <th>Description</th>
        <th>Result</th>
      </tr>
      {% for issue in issues %}
      <tr>
        <td><a href="{{ issue['pr_url'] }}">{{ issue['pr_id'] }}</a></td>
        <td>{{ issue['pr_desc'] }}</td>
        <td><a href="{{ issue['jira_url'] }}">{{ issue['result'] }}</a></td>
      </tr>
      {% endfor %}
    </table>
  </body>
</html>
"""


class new_session:
    """create a aiohttp client session context manager"""
    def __init__(self):
        self._s = aiohttp.ClientSession(headers=GITHUB_HEADERS)

    async def __aenter__(self):
        return self._s

    async def __aexit__(self, exc_type, exc_value, traceback):
        await self._s.close()


def coro(f):
    """decorator for click commands"""
    @wraps(f)
    def wrapper(*args, **kwargs):
        loop = asyncio.get_event_loop()
        return loop.run_until_complete(f(*args, **kwargs))
    return wrapper


def cook_repo_with_defaults(repo):
    """Deprecated, please use Project"""
    if '/' not in repo:
        owner = 'pingcap'
        if repo == 'tikv':
            owner = 'tikv'
        return f'{owner}/{repo}'
    return repo


def cook_binary_url(component, sha1):
    tar_name = f'{component}-server'
    return f'http://fileserver.pingcap.net/download/builds/pingcap/'\
        f'{component}/{sha1}/centos7/{tar_name}.tar.gz'


##################
# GitHub
##################


class GithubException(Exception):
    pass


class GithubClient:
    def __init__(self, session, timeout=2):
        self._s = session
        self._timeout = timeout
        self._base_uri = 'https://api.github.com'

    async def get_commit(self, owner, repo, ref, **kwargs):
        url = f'{self._base_uri}/repos/{owner}/{repo}/commits/{ref}'
        timeout = kwargs.get('timeout') or self._timeout
        async with self._s.get(url, timeout=timeout) as resp:
            if resp.status != 200:
                breakpoint()
                raise GithubException
            return await resp.json()


##########################
# jenkins
##########################

def create_jenkins_client(jenkins_id):
    if JenkinsId(jenkins_id) == JenkinsId.tidb:
        jenkins = Jenkins(TIDB_JENKINS_URI,
                          username=TIDB_JENKINS_USERNAME,
                          password=TIDB_JENKINS_PASSWORD)
    elif JenkinsId(jenkins_id) == JenkinsId.qa:
        jenkins = Jenkins(QA_JENKINS_URI,
                          username=QA_JENKINS_USERNAME,
                          password=QA_JENKINS_PASSWORD)
    else:
        jenkins = Jenkins(IDC_JENKINS_URI,
                          username=IDC_JENKINS_USERNAME,
                          password=IDC_JENKINS_PASSWORD)
    return jenkins


def get_job_jenkins_id(job):
    for jenkins_id, jobs in JenkinsJobsMapping.items():
        if job in jobs:
            return jenkins_id
    raise Exception("we don't record which jenkins run this job")


def query_record_status(record):
    """query build status by record

    :type record: BuildRecord
    """
    job = getattr(Job, record.name)
    jenkins_id = get_job_jenkins_id(job)
    client = create_jenkins_client(JenkinsId(jenkins_id))
    job_id = record.url.split('/')[-1]
    try:
        build_info = client.get_build_info(job.value, int(job_id))
    except JenkinsException:
        status = Status.pending
    else:
        result = build_info['result']
        if build_info['building']:
            status = Status.running
        else:
            if result == 'SUCCESS':
                status = Status.succeed
            elif result in ('FAILURE', 'ABORTED', 'UNSTABLE', 'NOT_BUILT'):
                status = Status.failed
            else:
                # HELP: maybe this will never happen?
                status = Status.created
    record = record._replace(status=status)
    return record


def gen_build_url(job, job_id):
    """generate build url

    :type job: Job
    :param job_id: jenkins build id
    """
    job = Job(job)
    jenkins_id = get_job_jenkins_id(job)
    if jenkins_id == JenkinsId.idc:
        jenkins_url = IDC_JENKINS_URI
    elif jenkins_id == JenkinsId.tidb:
        jenkins_url = TIDB_JENKINS_URI
    elif jenkins_id == JenkinsId.qa:
        jenkins_url = QA_JENKINS_URI
    else:
        raise Exception('unknown jenkins id')

    return f'{jenkins_url}/job/{job.value}/{job_id}'


def save_record(record):
    """
    save record in DBFILE
    """
    name, digest, url, status = record
    line = f'{name} {digest} {url}'
    if status is not None:
        line += f' {status.value}'
    with open(JENKINS_DBFILE, 'a') as f:
        f.write(line)
        f.write('\n')
    return url


def trigger_build(jenkins, job, params):
    job_name = job.value
    job_info = jenkins.get_job_info(job_name)
    job_id = job_info['nextBuildNumber']
    jenkins.build_job(job_name, params)
    return job_id


def hash_params(params):
    params_str = json.dumps(params, sort_keys=True)
    return hashlib.md5(params_str.encode('utf-8')).hexdigest()[:7]


def is_build_exists(job, digest):
    """
    :return: (flag, records)
    """
    flag, records = False, []
    with open(JENKINS_DBFILE) as f:
        for line in f:
            record = line2record(line)
            if record.name == job.name and record.digest == digest:
                flag = True
                records.append(record)
    return flag, records


def line2record(line):
    parts = line.strip().split(' ')
    if len(parts) >= 4:
        name, digest, url, status = parts
    else:
        name, digest, url = parts
        status = Status.unknown
    return BuildRecord(name, digest, url, Status(status))


def record2line(record):
    name, digest, url, status = record
    if status is None:
        return f'{name} {digest} {url}'
    return f'{name} {digest} {url} {status.value}'


def gen_record(job, digest, job_id, status=None):
    url = gen_build_url(job, job_id)
    return BuildRecord(job.name, digest, url, status)


def build_job(job, params, rerun=False):
    jenkins_id = get_job_jenkins_id(job)
    jenkins = create_jenkins_client(jenkins_id)
    digest = hash_params(params)
    exists, records = is_build_exists(job, digest)
    if (not exists) or rerun:
        job_id = trigger_build(jenkins, job, params)
        record = gen_record(job, digest, job_id)
        save_record(record)
        click.echo(record2line(record))
    else:
        click.echo(f'Record already exists:')
        click.echo(record2line(records[-1]))


##############################
# GitHub
##############################

async def list_repo_latest_commits(
        s, repo, sha='master', limit=None, since=None, timeout=5):
    """
    yield (sha, msg_title)
    """
    repo = cook_repo_with_defaults(repo)
    params = {'sha': sha}
    if since is not None:
        params['since'] = since
    url = f'https://api.github.com/repos/{repo}/commits'
    async with s.get(url, timeout=timeout, params=params) as resp:
        commits = await resp.json()
        if limit is not None:
            commits = commits[:limit]
        for commit in commits:
            yield commit


async def get_repo_commit(s, repo, sha1, timeout=2):
    """
    return (msg_title, author_name, date)
    """
    repo = cook_repo_with_defaults(repo)
    url = f'https://api.github.com/repos/{repo}/commits/{sha1}'
    async with s.get(url, timeout=timeout) as resp:
        commit = await resp.json()
        commit = commit['commit']
        author = commit['author']
        author_name = author['name']
        date = author['date']
        msg_title = commit['message'].split('\n\n')[0]
        return (msg_title, author_name, date)


async def get_latest_binary_sha1(
        s, repo, branch='master', timeout=2):
    url = f'http://fileserver.pingcap.net/download/refs/pingcap/{repo}/{branch}/sha1'
    async with s.get(url) as resp:
        return await resp.text()


#################
# jira issues
#################

def create_jira_client():
    return JIRA(JIRA_URI, auth=(JIRA_USERNAME, JIRA_PASSWORD))


def create_jira_issue(summary, description,
                      parent_task='QADEV-655', project='QADEV'):
    fields = {
        'project': {'key': project},
        'summary': summary,
        'description': description,
        'issuetype': 'Sub-task',
        'parent': {'key': parent_task}
    }
    jira = create_jira_client()
    return jira.create_issue(fields=fields)


def is_issue_created(sha):
    created = False
    with open(DBFILE) as f:
        for line in f:
            if line.startswith(sha):
                created = True
                break
    return created


def save_created_issue(sha, issue_key):
    with open(DBFILE, 'a') as f:
        f.write(f'{sha} {issue_key}\n')


def get_release_metadata(filename):
    """Parse release metadat from release-json file"""

    with open(filename) as f:
        js = json.load(f)
    branch = js.pop('release_branch')
    js.pop('tidb_old_commits')

    hashes = {}
    for key, value in js.items():
        project = getattr(Project, key[:-7])
        hash_ = value
        hashes[project] = hash_

    return {
        'branch': branch,
        'hashes': hashes
    }


########################
# bench
########################

def run_ycsb_bench(metadata, rerun):
    hashes = metadata['hashes']
    params = {
        'branch': 'master',  # non-related with branch
        'channel': '#benchbot_test',
        'tidb_version': f'hash:{hashes[Project.tidb]}',
        'tikv_version': f'hash:{hashes[Project.tikv]}',
        'pd_version': f'hash:{hashes[Project.pd]}',
        'types': 'mysql',
        'instance': '',
    }
    job = Job.bench_ycsb
    build_job(job, params, rerun=rerun)


def run_tpcc_bench(metadata, rerun):
    hashes = metadata['hashes']
    params = {
        'branch': metadata['branch'],
        'channel': '#benchbot_test',
        'tidb_version': f'hash:{hashes[Project.tidb]}',
        'tikv_version': f'hash:{hashes[Project.tikv]}',
        'pd_version': f'hash:{hashes[Project.pd]}',
        'repeat_time': 5,
        'instance': 'tpcc',
    }
    job = Job.bench_tpcc
    build_job(job, params, rerun=rerun)


def run_tpch_bench(metadata, rerun):
    hashes = metadata['hashes']
    params = {
        'branch': metadata['branch'],
        'channel': '#benchbot_test',
        'tidb_version': f'hash:{hashes[Project.tidb]}',
        'tikv_version': f'hash:{hashes[Project.tikv]}',
        'pd_version': f'hash:{hashes[Project.pd]}',
        'instance': 'tpch50',
    }
    job = Job.bench_tpch
    build_job(job, params, rerun=rerun)


def run_sysbench_bench(metadata, rerun):
    hashes = metadata['hashes']
    params = {
        'tidb_version': f'hash:{hashes[Project.tidb]}',
        'tikv_version': f'hash:{hashes[Project.tikv]}',
        'pd_version': f'hash:{hashes[Project.pd]}',
        'benchtime': 1200,  # recommended default value
        'benchcount': 10,   # recommended default value
        'channel': '#benchbot_test',
        'ansible_branch': metadata['branch'],
    }
    job = Job.bench_manual
    build_job(job, params, rerun=rerun)


def run_tiflash_case(metadata, case, run_time=720, rerun=False):
    """
    :param run_time: 720=0.5day
    """
    branch = metadata['branch']
    hashes = metadata['hashes']

    parts = case.split('-')
    testcase = parts[0]
    if len(parts) > 1:
        options = parts[1]
        for char in options:
            if char == '0':
                testcase += ' false'
            elif char == '1':
                testcase += ' true'
    params = {
        'branch': branch,
        'version': 'latest',
        'testcase': f'schrodinger/{testcase}',
        'maxRunTime': run_time,
        'tidb_commit_hash': hashes[Project.tidb],
        'tikv_commit_hash': hashes[Project.tikv],
        'pd_commit_hash': hashes[Project.pd],
        'tiflash_commit_hash': hashes[Project.tiflash],
        # 'notify': True,
        'idleMinutes': 5,
        'desc': f'triggered by QA for release({branch}) test',
    }
    job = Job.tiflash_test
    build_job(job, params, rerun=rerun)


def build_x(metadata, job, tag=None):
    """build one component(tidb/tikv/pd/...)"""
    branch = metadata['branch']
    params = {
        'FORK': 'pingcap',
        'BRANCH': branch,
    }
    if tag is not None:
        params['VERSION'] = tag
    build_job(job, params)


##########################
# sub commands
##########################

@click.group()
def cli():
    pass


@cli.command()
@click.argument('filename', type=click.Path(exists=True))
@coro
async def e2e(filename):
    """run e2e jenkins job"""
    metadata = get_release_metadata(filename)
    hashes = metadata['hashes']
    branch = metadata['branch']
    br = hashes[Project.br]
    tiflash = hashes[Project.tiflash]
    params = {
        'TIDB_BRANCH_OR_COMMIT': hashes[Project.tidb],
        'TIKV_BRANCH_OR_COMMIT': hashes[Project.tikv],
        'PD_BRANCH_OR_COMMIT': hashes[Project.pd],
        'BINLOG_BRANCH_OR_COMMIT': hashes[Project.binlog],
        'BR_BRANCH_AND_COMMIT': f'{branch}/{br}',
        'TICDC_BRANCH_OR_COMMIT': hashes[Project.ticdc],
        'TOOLS_BRANCH_OR_COMMIT': hashes[Project.tools],
        'TIFLASH_BRANCH_AND_COMMIT': f'{branch}/{tiflash}',
    }
    job = Job.e2e
    build_job(job, params)


@cli.command()
@click.argument('filename', type=click.Path(exists=True))
@click.option('-w', '--workload',
              type=click.Choice(['tpcc', 'tpch', 'ycsb', 'sysbench']))
@click.option('-a', '--all-workloads',
              is_flag=True, default=False)
@click.option('--rerun', is_flag=True, default=False)
@coro
async def bench(filename, workload, all_workloads, rerun):
    """run bench WORKLOAD"""
    metadata = get_release_metadata(filename)
    mapping = {
        'tpcc': run_tpcc_bench,
        'tpch': run_tpch_bench,
        'ycsb': run_ycsb_bench,
        'sysbench': run_sysbench_bench,
    }

    if all_workloads:
        for workload, func in mapping.items():
            func(metadata, rerun)
    else:
        if workload:
            runner = mapping[workload]
            runner(metadata, rerun)
        else:
            click.echo(click.style('Specify one workload!', fg='red'))
            sys.exit(1)


@cli.command()
@click.argument('filename', type=click.Path(exists=True))
@coro
async def tiflash_regression(filename):
    """run bench/tiflash_regresssion"""
    metadata = get_release_metadata(filename)
    hashes = metadata['hashes']
    branch = metadata['branch']
    params = {
        'branch': metadata['branch'],
        'version': 'latest',

        'tidb_commit_hash': hashes[Project.tidb],
        'tikv_commit_hash': hashes[Project.tikv],
        'pd_commit_hash': hashes[Project.pd],
        'tiflash_commit_hash': hashes[Project.tiflash],

        'idleMinutes': 180,
        'desc': f'release {branch} test',
    }
    job = Job.tiflash_regression
    build_job(job, params)


TIFLASH_CASES = [
    'bank',
    'bank2',
    'crud',
    'ledger',
    'sqllogic',
    'ddl',
    # region merge
    'bank-1',
    'bank2-1',
    'crud-1',
    'ledger-1',
    # optimistic
    'bank-0000',
    'bank2-0000',
    'crud-0000',
    'ledger-0000',
    # follower read
    'bank-00011'
]


@cli.command()
@click.argument('filename', type=click.Path(exists=True))
@click.option('--case', type=click.Choice(TIFLASH_CASES))
@click.option('--all-cases', is_flag=True, default=False)
@click.option('--rerun', is_flag=True, default=False)
@coro
async def tiflash_test(filename, case, all_cases, rerun):
    """run bench/tiflash_test"""
    metadata = get_release_metadata(filename)
    if all_cases:
        for case in TIFLASH_CASES:
            run_tiflash_case(metadata, case, rerun=rerun)
    else:
        if case:
            run_tiflash_case(metadata, case, rerun=rerun)
        else:
            click.echo(click.style('Specify one case!', fg='red'))


@cli.command()
@click.argument('filename', type=click.Path(exists=True))
@click.option('--tag')
@click.option('--component', type=click.Choice(['tidb', 'pd', 'tikv']))
@coro
async def build(filename, tag, component):
    """build XXX (maybe you should use build_all)"""
    metadata = get_release_metadata(filename)
    job_name = f'build_{component}'
    job = getattr(Job, job_name)
    build_x(metadata, job, tag)


@cli.command()
@click.argument('filename', type=click.Path(exists=True))
@click.argument('tag')
@coro
async def build_all(filename, tag):
    """run qa/build_all"""
    metadata = get_release_metadata(filename)
    params = {
        'FORK': 'pingcap',
        'BRANCH': metadata['branch'],
        'VERSION': tag,
        'TIUP_MIRRORS': 'http://172.16.4.61:31989',
    }
    job = Job.build_all
    build_job(job, params)


@cli.command()
@coro
async def check_status():
    jobs = {}  # {name: (digest, url, status)}
    # find the latest build for each job
    with open(JENKINS_DBFILE) as f:
        for line in f:
            record = line2record(line)
            jobs[record.name] = record
    loop = asyncio.get_event_loop()
    outputs = []
    tasks = []
    origin_records = []

    # filter out builds which are finished
    for name, record in jobs.items():
        _, digest, url, status = record
        if status in (Status.succeed, Status.failed):
            outputs.append(f'{name:20}\t{status.value:10}\t{url}')
            continue
        origin_records.append(record)
        task = loop.run_in_executor(None, query_record_status, record)
        tasks.append(task)

    # query builds status and generate outputs
    records = await asyncio.gather(*tasks)
    for i, record in enumerate(records):
        if record != origin_records[i]:
            save_record(record)
        name, _, url, status = record
        outputs.append(f'{name:20}\t{status.value:10}\t{url}')

    # colorize outputs
    for output in outputs:
        _, status, _ = output.split('\t')
        status = Status(status.strip())
        if status == Status.failed:
            styled_output = click.style(output, fg='red')
        elif status == Status.succeed:
            styled_output = click.style(output, fg='green')
        else:
            styled_output = output
        click.echo(styled_output)


@cli.command()
@click.argument('filename', type=click.Path(exists=True))
@click.option('--rewrite', is_flag=True, default=False)
@coro
async def check_hash(filename, rewrite):
    """check if the hash in FILENAME is the latest one"""
    with open(filename) as f:
        origin_js = json.load(f)
        js = origin_js.copy()

    release_branch = js.pop('release_branch')
    js.pop('tidb_old_commits')

    async with new_session() as s:
        client = GithubClient(s)

        async def _cmp(name, sha):
            project = getattr(Project, name)
            branch = release_branch
            # tools use master as it's release_branch
            if project is Project.tools:
                branch = 'master'
            owner, repo = project.value.split('/')
            commit = await client.get_commit(owner, repo, branch, timeout=3)
            latest_sha = commit['sha']
            is_latest = latest_sha == sha
            return name, latest_sha, is_latest, sha

        for task in asyncio.as_completed(
                [_cmp(key[:-7], value) for key, value in js.items()]):
            name, latest_sha, is_latest, sha = await task
            if not is_latest:
                origin_js[f'{name}_commit'] = latest_sha
            green_line = f'{name:12}\t----\t{latest_sha}'
            line = f'{name:12}\t{is_latest}\t{sha}'
            if not is_latest:
                click.echo(click.style(green_line, fg='green'))
                click.echo(click.style(line, fg='red'))
            else:
                click.echo(line)

        if rewrite:
            with open(filename, 'w') as f:
                json.dump(origin_js, f, indent=4)
            click.echo('rewrite succeed!')
    click.echo('https://github.com/pingcap/tidb-prm/issues/20')


@cli.command()
@click.argument('repo', default='tidb')
@click.argument('sha', default='master')
@click.option('-v', '--verbose', count=True)
@coro
async def artifacts(repo, sha, verbose):
    """show artifacts of REPO/SHA

    \b
    Usage examples:

    * tirelease artifacts tidb release-4.0
    """
    click.echo(f'{repo}#{sha}', nl=False)

    loop = asyncio.get_event_loop()
    is_branch = len(sha) != 40
    async with new_session() as s:
        if is_branch:
            click.echo()
            latest_binary_sha1 = await get_latest_binary_sha1(s, repo, sha)
            latest_binary_sha1 = latest_binary_sha1.strip()
            async for commit in list_repo_latest_commits(s, repo, sha, limit=5):
                sha1, _ = commit['sha'], commit['commit']['message'].split('\n\n')[0]
                if sha1 == latest_binary_sha1:
                    sha1_styled = click.style(sha1, fg='green')
                else:
                    sha1_styled = sha1
                click.echo(f'    {sha1_styled}')
            binary_url = cook_binary_url(repo, latest_binary_sha1)
            click.echo(f'url: {binary_url}')
        else:
            task = loop.create_task(get_repo_commit(s, repo, sha))
            binary_url = cook_binary_url(repo, sha)
            resp = await s.head(binary_url)
            ok = resp.status == 200
            if ok:
                status = click.style('ok', fg='green')
            else:
                status = click.style('not found', fg='red')
            click.echo(f' ...{status}')

            msg_title, author_name, date = await task
            click.echo(f'    {msg_title}')
            click.echo(f'    {author_name} - {date}')
            if ok:
                click.echo(f'{binary_url}')
            else:
                sys.exit(1)


@cli.command()
@click.argument('issue')
@coro
async def report_bugfix(issue):
    query = f'parent={issue}'
    jira = create_jira_client()
    max_total = 200
    issues = jira.search_issues(query, maxResults=max_total)
    if len(issues) >= max_total:
        raise Exception('too many issues!')

    # collect all valid issues
    cancelled = 0
    done_issues = []
    for issue in issues:
        status = issue.fields.status.name.lower()
        if status != 'done':
            cancelled += 1
            continue
        pr_url = issue.fields.description
        pr_url = pr_url.split('\n')[0]
        pr_id = pr_url.split('/')[-1]
        assert pr_url.startswith('https')
        assert pr_id.isdigit()
        done_issues.append({'pr_url': pr_url,
                            'pr_id': pr_id,
                            'pr_desc': issue.fields.summary,
                            'jira_url': issue.permalink(),
                            'result': 'passed'})

    # render template and generate html file
    tpl = Template(BUGFIX_REPORT_TEMPLATE)
    text = tpl.render(issues=done_issues)
    filename = 'bugfix_report.html'
    with open(filename, 'w') as f:
        f.write(text)
    click.echo(f'Total: {len(done_issues)}, cancelled: {cancelled}')
    click.echo('Generated: ' + click.style(filename, fg='green'))


@cli.command()
@click.argument('repo')
@click.argument('sha')
@click.option('--dry-run/--no-dry-run', is_flag=True, default=True)
@click.option('-v', '--verbose', count=True)
@coro
async def pr2jira(repo, sha, dry_run, verbose):
    """create issue on Jira for each commit(PR) in REPO/SHA

    \b
    Usage examples:

    * tirelease pr2jira tidb release-4.0 --no-dry-run
    """
    click.echo(f'{repo}#{sha}{" | dry-run" if dry_run else ""}', nl=False)

    async with new_session() as s:
        click.echo()
        commits = list_repo_latest_commits(s, repo, sha,
                                           since="2020-07-18T00:00:00Z")
        async for commit in commits:
            commit_sha = commit['sha']
            message = commit['commit']['message'].split('\n\n')[0]
            msg, pr_id_str = message.rsplit(' ', 1)
            p = re.compile(r'\(#(\d+)\)')
            m = p.match(pr_id_str)
            if m:
                pr_id = m.group(1)
            else:
                text = click.style(f'commit:{commit_sha} has no corresponding PR',
                                   fg='red')
                click.echo(text)
                sys.exit(1)

            if not is_issue_created(commit_sha):
                repo_with_ns = cook_repo_with_defaults(repo)
                summary = msg
                description = f'https://github.com/{repo_with_ns}/pull/{pr_id}'
                if not dry_run:
                    issue = create_jira_issue(summary, description)
                    issue_key = issue.key
                    save_created_issue(commit_sha, issue_key)
                else:
                    issue_key = 'QADEV-XXX'
                click.echo(f'sub-task created: {issue_key} {pr_id} {commit_sha}')
            else:
                click.echo(f'already created: {commit_sha}')


if __name__ == '__main__':
    cli()
